# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aQv5I4JshLz39gtV8_vQGTyAeMUxMExb

# DL implementation of abstractive summarization by finetuning PEGASUS model

## Required libraries are imported or installed
"""

!pip install sentencepiece
!pip install transformers
!pip install datasets
!pip install rouge_score

from transformers import PegasusForConditionalGeneration, PegasusTokenizer, Trainer, TrainingArguments
from datasets import load_metric
from rouge_score import rouge_scorer
from tqdm import tqdm
import torch
import pandas as pd
import numpy as np

"""## Required functions"""

class PegasusDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels
    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  
        return item
    def __len__(self):
        return len(self.labels)

def tokenize_data(texts, labels):
  encodings = tokenizer(texts, truncation=True, padding=True, return_tensors="pt")
  decodings = tokenizer(labels, truncation=True, padding=True, return_tensors="pt")
  dataset_tokenized = PegasusDataset(encodings, decodings)
  return dataset_tokenized

def prepare_data(model_name, train_texts, train_labels, 
                 val_texts, val_labels, test_texts, test_labels):

  train_dataset = tokenize_data(train_texts, train_labels)
  val_dataset = tokenize_data(val_texts, val_labels) 
  test_dataset = tokenize_data(test_texts, test_labels) 

  return train_dataset, val_dataset, test_dataset

def prepare_fine_tuning(model, train_dataset, val_dataset, freeze_encoder=False, output_dir='./results'):

  if freeze_encoder:
    for param in model.model.encoder.parameters():
      param.requires_grad = False

  training_args = TrainingArguments(
    output_dir = output_dir,
    do_train = True, 
    num_train_epochs=2,              
    per_device_train_batch_size=1,   
    save_steps=500,                  
    save_total_limit=5,              
    evaluation_strategy='steps',     
    eval_steps=100,                  
    warmup_steps=500,                
    weight_decay=0.01,               
    logging_dir='./logs',            
    logging_steps=10,
  )

  trainer = Trainer(
    model=model,                         
    args=training_args,                  
    train_dataset=train_dataset,         
    eval_dataset=val_dataset             
  )

  return trainer

def compute_rouge(txt,ref):
  rs_1 = rouge.compute(predictions=txt, references=ref, rouge_types=["rouge1"])["rouge1"].high
  rs_2 = rouge.compute(predictions=txt, references=ref, rouge_types=["rouge2"])["rouge2"].high
  rs_L = rouge.compute(predictions=txt, references=ref, rouge_types=["rougeL"])["rougeL"].high
  return rs_1, rs_2, rs_L

"""## Data modification

### Data cleaning and preparing
"""

!gdown https://drive.google.com/uc?id=1kY6AEpZHEbqqFh_te_ITybsE4R9xEOa9

!unzip '/content/archive.zip'
!rm /content/archive.zip

df = pd.read_csv('news_summary.csv', encoding = "ISO-8859-1")

print(df.shape)

df.dropna(subset = ["ctext"], inplace=True)

df.head()

lst = []
for i in range(len(df)):
  lst.append(i)
df.index = lst

print(df.shape)

"""### Train-validation-Test data spliting"""

train_texts, train_labels = df["ctext"][:3500], df["text"][:3500]
val_texts, val_labels = df["ctext"][3500:4000], df["text"][3500:4000]
test_texts, test_labels = df["ctext"][4000:], df["text"][4000:]

train_texts = list(train_texts)
train_labels = list(train_labels)
val_texts = list(val_texts)
val_labels = list(val_labels)
test_texts = list(test_texts)
test_labels = list(test_labels)

"""## Preparing the data according to PEGASUS model requirements"""

model_name = 'google/pegasus-large'
tokenizer = PegasusTokenizer.from_pretrained(model_name)
train_dataset, val_dataset, test_dataset = prepare_data(model_name, train_texts, train_labels, val_texts, val_labels, test_texts, test_labels)
device = 'cuda' if torch.cuda.is_available() else 'cpu'

"""## Finetune model and train"""

model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)
trainer = prepare_fine_tuning(model, train_dataset, val_dataset)

"""## Testing the finetuned model on test dataset """

trainer.evaluate(test_dataset)

Rouge_1 = []
Rouge_2 = []
Rouge_L = []
rouge = load_metric("rouge")
for i in tqdm(range(len(test_texts))):
  mydict = {}
  mydict['input_ids'] = test_dataset.encodings['input_ids'][i].view(1, -1).to(device)
  mydict['attention_mask'] = test_dataset.encodings['attention_mask'][i].view(1, -1).to(device)
  ref = [test_labels[i]]
  s = trainer.model.generate(**mydict)
  txt = tokenizer.batch_decode(s, skip_special_tokens=True)
  (rs_1, rs_2, rs_L) = compute_rouge(txt,ref)
  Rouge_1.append(rs_1)
  Rouge_2.append(rs_2)
  Rouge_L.append(rs_L)

k1_p = 0; k1_r = 0; k1_f = 0
k2_p = 0; k2_r = 0; k2_f = 0
kl_p = 0; kl_r = 0; kl_f = 0
for i in range(len(Rouge_1)):
  k1_p += Rouge_1[i][0]
  k1_r += Rouge_1[i][1]
  k1_f += Rouge_1[i][2]
  R1_p = (k1_p/len(Rouge_1)*100)
  R1_r = (k1_r/len(Rouge_1)*100)
  R1_f = (k1_f/len(Rouge_1)*100)
 
  k2_p += Rouge_2[i][0]
  k2_r += Rouge_2[i][1]
  k2_f += Rouge_2[i][2]
  R2_p = (k2_p/len(Rouge_2)*100)
  R2_r = (k2_r/len(Rouge_2)*100)
  R2_f = (k2_f/len(Rouge_2)*100)

  kl_p += Rouge_L[i][0]
  kl_r += Rouge_L[i][1]
  kl_f += Rouge_L[i][2]
  RL_p = (kl_p/len(Rouge_L)*100)
  RL_r = (kl_r/len(Rouge_L)*100)
  RL_f = (kl_f/len(Rouge_L)*100)

print(".........Rouge1.........")
print("Precision: {:.2f}, Recall: {:.2f}, F1 measure: {:.2f}".format(R1_p,R1_r,R1_f))
print("-"*50)
print(".........Rouge2.........")
print("Precision: {:.2f}, Recall: {:.2f}, F1 measure: {:.2f}".format(R2_p,R2_r,R2_f))
print("-"*50)
print(".........RougeL.........")
print("Precision: {:.2f}, Recall: {:.2f}, F1 measure: {:.2f}".format(RL_p,RL_r,RL_f))
print("-"*50)

"""## Demonstration on four example summaries

### Example 1
"""

src = [test_texts[0]]
ref = [test_labels[0]]
batch = tokenizer(src, truncation=True, return_tensors="pt").to(device)
summarized = trainer.model.generate(**batch)
txt = tokenizer.batch_decode(summarized, skip_special_tokens=True)
rouge_score = rouge.compute(predictions=txt, references=ref, rouge_types=["rouge1"])["rouge1"].high

print(ref)  #original summary
print("-"*50)
print(txt)  #generated summary
print("-"*50)
print("Rouge1 score {}".format(rouge_score))

"""### Example 2"""

src = [test_texts[120]]
ref = [test_labels[120]]
batch = tokenizer(src, truncation=True, return_tensors="pt").to(device)
summarized = trainer.model.generate(**batch)
txt = tokenizer.batch_decode(summarized, skip_special_tokens=True)
rouge_score = rouge.compute(predictions=txt, references=ref, rouge_types=["rouge1"])["rouge1"].high

print(ref)  #original summary
print("-"*50)
print(txt)  #generated summary
print("-"*50)
print("Rouge1 score {}".format(rouge_score))

"""### Example 3"""

src = [test_texts[-20]]
ref = [test_labels[-20]]
batch = tokenizer(src, truncation=True, return_tensors="pt").to(device)
summarized = trainer.model.generate(**batch)
txt = tokenizer.batch_decode(summarized, skip_special_tokens=True)
rouge_score = rouge.compute(predictions=txt, references=ref, rouge_types=["rouge1"])["rouge1"].high

print(ref)  #original summary
print("-"*50)
print(txt)  #generated summary
print("-"*50)
print("Rouge1 score {}".format(rouge_score))

"""### Example 4"""

src = [test_texts[300]]
ref = [test_labels[300]]
batch = tokenizer(src, truncation=True, return_tensors="pt").to(device)
summarized = trainer.model.generate(**batch)
txt = tokenizer.batch_decode(summarized, skip_special_tokens=True)
rouge_score = rouge.compute(predictions=txt, references=ref, rouge_types=["rouge1"])["rouge1"].high

print(ref)  #original summary
print("-"*50)
print(txt)  #generated summary
print("-"*50)
print("Rouge1 score {}".format(rouge_score))



"""# BONUS part

## 5-Fold maunal assessment
"""

# Import required libraries
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import sklearn

# Import necessary modules
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from math import sqrt
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import KFold
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import LeavePOut
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import StratifiedKFold

kfold = model_selection.KFold(n_splits=5)
model_kfold = trainer.model
results_kfold = model_selection.cross_val_score(model_kfold, train_texts, train_labels, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfold.mean()*100.0))

